{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "331b536c-753d-49f8-8a7d-74eefae88e76",
   "metadata": {},
   "source": [
    "### Plan\n",
    "\n",
    "1. Download a bunch of World Bank document metadata using API\n",
    "2. Build ontology using the metadata\n",
    "3. Build a knowledge graph (KG) by populating ontology with instances of World Bank documents (each row in the metadata)\n",
    "4. Bring in some additional data from Wikidata\n",
    "5. Query KG using SPARQL\n",
    "6. Compare the different ways of interacting with data: using SPARQL queries on the RDF, putting raw metadata into LlamaIndex, and putting the RDF data into LlamaIndex\n",
    "\n",
    "See accompanying blog post on Medium for full documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796996c-2e8f-4bf0-ab6e-1bc88de8b874",
   "metadata": {},
   "source": [
    "## 1. Download some World Bank document metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "a0786b86-899c-4322-8c83-3ab6b1f9f05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "url = 'https://search.worldbank.org/api/v2/wds'\n",
    "params = {\n",
    "    'format': 'json',\n",
    "    'display_title': '\"sustainable development\"',\n",
    "    'rows': 100, #Can adjust this to get more/less data\n",
    "    'page': 1\n",
    "}\n",
    "\n",
    "metadata_list = []\n",
    "\n",
    "for i in range(1):\n",
    "    response = requests.get(url, params=params)\n",
    "    data = json.loads(response.content)\n",
    "    for doc_id in data['documents']:\n",
    "        metadata = data['documents'][doc_id]\n",
    "        metadata_list.append(metadata)\n",
    "        \n",
    "    params['page'] += 1\n",
    "    \n",
    "df = pd.DataFrame(metadata_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "cb810d7c-fbc4-412e-b6ca-39ac77ec6e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save raw data to a csv so we can compare results later\n",
    "df.to_csv(\"raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31552c-8b28-4b19-a8ec-b8696af06165",
   "metadata": {},
   "source": [
    "## 2. Use metadata to create ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "6da33bd9-210c-47c5-8d2b-ab223f9a569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, RDF, RDFS, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import SKOS, XSD\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a new RDF graph\n",
    "g = Graph()\n",
    "\n",
    "schema = Namespace('http://schema.org/')\n",
    "wd = Namespace('http://www.wikidata.org/entity/')\n",
    "\n",
    "# Define namespaces\n",
    "prefixes = {\n",
    "    'schema': schema,\n",
    "    'wd': wd,\n",
    "    'skos': SKOS,\n",
    "    'xsd': XSD\n",
    "}\n",
    "for p, ns in prefixes.items():\n",
    "    g.bind(p, ns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "4da32052-9a0b-4cc3-8a55-fd4aaa544c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_label(entity_code):\n",
    "    # Set up the SPARQL endpoint\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "    # Construct the SPARQL query\n",
    "    query = f\"\"\"\n",
    "    SELECT ?label WHERE {{\n",
    "      wd:{entity_code} rdfs:label ?label.\n",
    "      FILTER (lang(?label) = 'en')\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the query and response format\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    # Execute the query and retrieve the results\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    # Extract and return the entity label\n",
    "    if 'results' in results and 'bindings' in results['results'] and results['results']['bindings']:\n",
    "        label = results['results']['bindings'][0]['label']['value']\n",
    "        return label\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "19fd8414-7532-4140-a6f9-3f3c7afbfca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subclass_country(column):\n",
    "    #This puts all entities in this column under the class 'country' when some of them are regions like MENA or continents like Africa. \n",
    "    newClass = URIRef(schema + \"country\")\n",
    "    g.add((newClass, RDFS.label, Literal(\"country\", lang='en')))\n",
    "    df[column] = df[column].astype(str)\n",
    "    for value in df[column].unique():\n",
    "        if value != \"nan\":\n",
    "            # Check Wikidata for a matching class\n",
    "            sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "            query = f\"\"\"\n",
    "                SELECT ?class ?label WHERE {{\n",
    "                    ?class wdt:P31 wd:Q6256 .\n",
    "                    ?class rdfs:label \"{value}\"@en .\n",
    "                    OPTIONAL {{ ?class skos:prefLabel ?label FILTER(lang(?label) = \"en\") }}\n",
    "                    FILTER(REGEX(STR(?class), \"^http://www.wikidata.org/entity/Q[0-9]+$\"))\n",
    "                }}\n",
    "            \"\"\"\n",
    "            sparql.setQuery(query)\n",
    "            sparql.setReturnFormat(JSON)\n",
    "            results = sparql.query().convert()\n",
    "\n",
    "            # If there is a match, use the Wikidata class as a subclass\n",
    "            if results['results']['bindings']:\n",
    "                #Get URI from Wikidata\n",
    "                uri = results['results']['bindings'][0]['class']['value']\n",
    "                #Get the 'Q ID' which is the unique ID at the end of the URI\n",
    "                qid = uri.split('/')[-1]\n",
    "                country_label = value\n",
    "                #Create a subclass for each country under the country class\n",
    "                subclass = URIRef(schema + country_label.replace(' ', '_'))\n",
    "                g.add((subclass, RDF.type, RDFS.Class))\n",
    "                g.add((subclass, RDFS.subClassOf, newClass))\n",
    "                # Update the \"country_URI\" column with the URI for the current country\n",
    "                df.loc[df[column] == value, \"country_URI\"] = uri\n",
    "                uri = URIRef(uri)\n",
    "                # Define the URI for the new Wikidata URI property\n",
    "                wd_URI_property = URIRef(schema + \"wd_URI\")\n",
    "                # Add the property to the RDF graph\n",
    "                g.add((wd_URI_property, RDF.type, RDF.Property))\n",
    "                # Add a label to the property\n",
    "                label = Literal(\"Wikidata URI\", lang=\"en\")\n",
    "                g.add((wd_URI_property, RDFS.label, label))\n",
    "                #Add Wikidata URI as a property to each country class\n",
    "                g.add((subclass, schema.wd_URI, uri))\n",
    "                #Add label to each Wikidata Q ID code that it is the Q ID for this particular country\n",
    "                g.add((uri, RDFS.label, Literal(f\"{country_label} wikidata code\", lang='en')))\n",
    "                g.add((subclass, RDFS.label, Literal(value, lang='en')))\n",
    "            else:    \n",
    "                subclass = URIRef(schema + value.replace(' ', '_').replace('-','_'))\n",
    "                g.add((subclass, RDF.type, RDFS.Class))\n",
    "                g.add((subclass, RDFS.subClassOf, newClass))\n",
    "                g.add((subclass, RDFS.label, Literal(value, lang='en')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "606796fa-edd7-4d54-8dd6-3784018b657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subclass_world_bank_document(column):\n",
    "    newClass = URIRef(schema + \"world_bank_document\")\n",
    "    g.add((newClass, RDFS.label, Literal(\"A document produced and written by the World Bank.\", lang='en')))   \n",
    "    df[column] = df[column].astype(str)\n",
    "    for value in df[column].unique():\n",
    "        if isinstance(value, str):\n",
    "            # Check Wikidata for a matching class\n",
    "            sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "            query = f\"\"\"\n",
    "                SELECT ?class ?label WHERE {{\n",
    "                    ?class rdfs:label \"{value}\"@en .\n",
    "                    OPTIONAL {{ ?class skos:prefLabel ?label FILTER(lang(?label) = \"en\") }}\n",
    "                    FILTER(REGEX(STR(?class), \"^http://www.wikidata.org/entity/Q[0-9]+$\"))\n",
    "                }}\n",
    "            \"\"\"\n",
    "            \n",
    "            sparql.setQuery(query)\n",
    "            sparql.setReturnFormat(JSON)\n",
    "            results = sparql.query().convert()\n",
    "            if value != \"nan\":\n",
    "                # If there is a match, use the Wikidata class as a subclass\n",
    "                if results['results']['bindings']:\n",
    "                    wd_class = results['results']['bindings'][0]['class']['value']\n",
    "                    #subclass = URIRef(wd_class)\n",
    "                    qid = wd_class.split('/')[-1]\n",
    "                    #label = get_entity_label(qid)\n",
    "                    label = value\n",
    "                    #print(label)\n",
    "                    subclass = URIRef(schema + label.replace(' ', '_'))\n",
    "                    #label = Literal(results['results']['bindings'][0]['label']['value']) if 'label' in results['results']['bindings'][0] else Literal(value, lang='en')\n",
    "                    g.add((subclass, RDF.type, RDFS.Class))\n",
    "                    #g.add((subclass, RDFS.subClassOf, schema[column]))\n",
    "                    g.add((subclass, RDFS.subClassOf, newClass))\n",
    "\n",
    "                    wd_uri = URIRef(wd_class)\n",
    "\n",
    "                    # Define the URI for the new property\n",
    "                    wd_URI_property = URIRef(schema + \"wd_URI\")\n",
    "\n",
    "                    # Add the property to the RDF graph\n",
    "                    g.add((wd_URI_property, RDF.type, RDF.Property))\n",
    "\n",
    "                    # Add a label to the property\n",
    "                    label = Literal(\"Wikidata URI\", lang=\"en\")\n",
    "                    g.add((wd_URI_property, RDFS.label, label))\n",
    "\n",
    "                    g.add((subclass, schema.wd_URI, wd_uri))\n",
    "                    g.add((wd_uri, RDFS.label, Literal(\"entity wikidata code\", lang='en')))\n",
    "                    #g.add((subclass, SKOS.prefLabel, Literal(value, lang='en')))\n",
    "                    g.add((subclass, RDFS.label, Literal(value, lang='en')))\n",
    "                    df[column] = df[column].replace(value, str(subclass))\n",
    "\n",
    "                else:\n",
    "                    subclass = URIRef(schema + value.replace(' ', '_').replace('-','_'))\n",
    "                    g.add((subclass, RDF.type, RDFS.Class))\n",
    "                    g.add((subclass, RDFS.subClassOf, newClass))\n",
    "                    #g.add((subclass, SKOS.prefLabel, Literal(value, lang='en')))\n",
    "                    g.add((subclass, RDFS.label, Literal(value, lang='en')))\n",
    "                    df[column] = df[column].replace(value, str(subclass))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "b996443a-0bfd-4d75-8867-a61ed5227b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subclass_multiple_values(column, names = None):\n",
    "    newClass = URIRef(schema + str(column))\n",
    "    df[column] = df[column].astype(str)\n",
    "    for rowValue in df[column].unique():\n",
    "        values = rowValue.split(\",\")\n",
    "        if names is not None:\n",
    "            for value in values:\n",
    "                newID = URIRef(schema + str(column) + \"/\" + str(value))\n",
    "                g.add((newID, RDF.type, newClass))\n",
    "                if value in names:\n",
    "                    name = names[value]\n",
    "                    g.add((newID, SKOS.prefLabel, Literal(name, lang='en')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "50124258-01d2-44dd-9b61-b4380726e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subclass_trustfund(column, ids = None):\n",
    "    df['trustfund'] = df['trustfund'].astype(str).str.replace('\\n', '').str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
    "    newClass = URIRef(schema + \"trustfund\")\n",
    "    g.add((newClass, RDFS.label, Literal(\"trustfund\")))\n",
    "    #RDFLoader doesn't allow a comment unless you also add a label on it\n",
    "    #g.add((newClass, RDFS.comment, Literal(\"The World Bank Group (WBG) uses trust funds, a financing arrangement set up with contributions from one or more development partner, to complement core funding from the International Bank for Reconstruction and Development (IBRD), the International Development Association (IDA), and the International Finance Corporation (IFC), in support of the World Bank Group’s goals. Trust funds allow the Bank to mobilize and direct concessional resources to strategic development priorities and to mobilize the resources and capabilities of other development actors through partnership programs.\")))\n",
    "\n",
    "    # Define the id property\n",
    "    id_property = schema.identifier\n",
    "    g.add((id_property, RDF.type, RDF.Property))\n",
    "    g.add((id_property, RDFS.label, Literal(\"Identifier\")))\n",
    "    #g.add((id_property, RDFS.comment, Literal(\"The unique identifier of the trustfund.\")))\n",
    "\n",
    "    # Associate the id property with the trustfund class\n",
    "    g.add((id_property, RDFS.domain, newClass))\n",
    "\n",
    "    df[column] = df[column].astype(str)\n",
    "    for rowValue in df[column].unique():\n",
    "        if rowValue != \"nan\":\n",
    "            names = rowValue.split(\",\")\n",
    "            if ids is not None:\n",
    "                for name in names:\n",
    "                    newID = URIRef(schema + \"trustfund\" + \"/\" + str(name))\n",
    "                    g.add((newID, RDF.type, newClass))\n",
    "                    g.add((newID, RDFS.label, Literal(str(name))))\n",
    "                    if name in ids:\n",
    "                        id = ids[name]\n",
    "                        # Create a URIRef for the trustfund_id resource\n",
    "                        trustfund_id = URIRef(schema + \"trustfund\" + \"/id/\" + Literal(id, datatype=XSD.string))\n",
    "                        g.add((newID, id_property, trustfund_id))\n",
    "                        #label = Literal(\"TEST\")\n",
    "                        label = Literal(f\"world bank trustfund ID for {name}\", lang=\"en\")\n",
    "                        g.add((trustfund_id, RDFS.label, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "647b39a4-f8ef-4ac7-8294-2517abf25142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subclass_project(column):\n",
    "    newClass = URIRef(schema + \"project\")\n",
    "    g.add((newClass, RDFS.label, Literal(\"worldbank project\")))\n",
    "\n",
    "    df[column] = df[column].astype(str)\n",
    "    for value in df[column].unique():\n",
    "        if value != \"nan\":\n",
    "            newID = URIRef(schema + \"project/\" + str(value).replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "            g.add((newID, RDF.type, newClass))\n",
    "            g.add((newID, RDFS.label, Literal(str(value).replace(\" \",\"_\").replace(\"-\",\"_\"), lang='en')))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "5984e872-5b10-4b7a-a4cb-11e130a8cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subclass_authors(column):\n",
    "    newClass = URIRef(schema + str(column))\n",
    "    g.add((newClass, RDFS.label, Literal(\"worldbank authors\")))\n",
    "    df[column] = df[column].astype(str)\n",
    "    for value in df[column].unique():\n",
    "        if value != \"nan\":\n",
    "            # Add author property for each author\n",
    "            author_dict = ast.literal_eval(value)\n",
    "            for author_dict_entries in author_dict.values():\n",
    "                author_name = author_dict_entries['author']\n",
    "                author_uri = URIRef(schema + \"author/\" + author_name.replace(\" \", \"_\"))\n",
    "                g.add((author_uri, RDF.type, newClass))\n",
    "                #g.add((author_uri, schema.name, Literal(author_name, lang='en')))\n",
    "                g.add((author_uri, RDFS.label, Literal(author_name, lang='en')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "6404ae66-d8f9-46e0-8e2a-15addcc0d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'trustfund_key' column to string\n",
    "df['trustfund_key'] = df['trustfund_key'].astype(str)\n",
    "df['trustfund'] = df['trustfund'].astype(str)\n",
    "\n",
    "# Create a dictionary that maps trustfund keys to trustfund names\n",
    "trustfund_dict = {}\n",
    "for i, row in df.iterrows():\n",
    "    keys = row['trustfund'].split(',')\n",
    "    values = row['trustfund_key'].split(',')\n",
    "    for key, value in zip(keys, values):\n",
    "        trustfund_dict[key.strip()] = value.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "f60b1ee3-771a-4f9d-8e22-9d19d39cb00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'trustfund_key' column to string\n",
    "df['projectid'] = df['projectid'].astype(str)\n",
    "df['projn'] = df['projn'].astype(str)\n",
    "\n",
    "# Create a dictionary that maps trustfund keys to trustfund names\n",
    "project_dict = {}\n",
    "for i, row in df.iterrows():\n",
    "    keys = row['projectid'].split(',')\n",
    "    values = row['projn'].split(',')\n",
    "    for key, value in zip(keys, values):\n",
    "        project_dict[key.strip()] = value.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "f14a9e1c-a3e7-4525-9999-b1e129573ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_subclass_country('count')\n",
    "create_subclass_world_bank_document('docty')\n",
    "create_subclass_trustfund('trustfund', trustfund_dict)\n",
    "create_subclass_project('projn')\n",
    "create_subclass_authors('authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "0ff782ee-ee99-40d6-8132-cfeb0a81f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevehedden/.local/lib/python3.8/site-packages/rdflib/plugins/serializers/nt.py:35: UserWarning: NTSerializer always uses UTF-8 encoding. Given encoding was: urf-8\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nebe42be5141842bbbd6e8cbc72b14459 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save as a ttl file to view in protege\n",
    "#Also save as ntriples which works better for the LlamaIndex RDFReader\n",
    "g.serialize('SDKG.ttl',format='turtle',prefixes = prefixes, encoding='urf-8')\n",
    "g.serialize(\"SDKG_nt\",format=\"nt\",prefixes = prefixes, encoding='urf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef6cc37-efdf-4dc4-a62a-8c3a0fb45e71",
   "metadata": {},
   "source": [
    "## 3. Build a knowledge graph (KG) by populating ontology with instances of World Bank documents (each row in the metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "fcaa380f-c770-4e0e-868f-57af7e2b2025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:00, 2604.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#Create abstract property\n",
    "df['abstracts'] = df['abstracts'].astype(str).str.replace('\\n', '').replace('\\\\n','')\n",
    "abstractIs_uri = URIRef(schema + \"abstractIs\")\n",
    "g.add((abstractIs_uri, RDF.type, RDF.Property))\n",
    "g.add((abstractIs_uri, RDFS.label, Literal(\"Short summary of the document.\")))\n",
    "\n",
    "#Create abstract class\n",
    "abstract_class = URIRef(schema + \"abstract\")\n",
    "g.add((abstract_class, RDFS.label, Literal(\"Short summary of a document.\")))\n",
    "\n",
    "#Create author properties\n",
    "authoredBy_uri = URIRef(schema + \"authoredBy\")\n",
    "authored_uri = URIRef(schema + \"authored\")\n",
    "g.add((authoredBy_uri, RDF.type, RDF.Property))\n",
    "g.add((authored_uri, RDF.type, RDF.Property))\n",
    "g.add((authoredBy_uri, RDFS.label, Literal(\"This document was authored by this author.\")))\n",
    "g.add((authored_uri, RDFS.label, Literal(\"This author wrote this document.\")))\n",
    "\n",
    "#Define 'part of' property\n",
    "isPartOf_uri = URIRef(schema + \"isPartOf\")\n",
    "g.add((isPartOf_uri, RDF.type, RDF.Property))\n",
    "g.add((isPartOf_uri, RDFS.label, Literal(\"This entity is a part of another entity\")))\n",
    "\n",
    "#Define 'countryOfOrigin' property\n",
    "countryOfOrigin_uri = URIRef(schema + \"countryOfOrigin\")\n",
    "g.add((countryOfOrigin_uri, RDF.type, RDF.Property))\n",
    "g.add((countryOfOrigin_uri, RDFS.label, Literal(\"Country that this document is about.\")))\n",
    "\n",
    "# Create instances for each document and add author property\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    if not pd.isnull(row['id']) and not pd.isnull(row['docty']) and not pd.isnull(row['authors']):\n",
    "        try:\n",
    "            # Create the report instance\n",
    "            instance = URIRef(schema + \"doc/\" + str(row['display_title']).replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "            g.add((instance, RDFS.label, Literal(str(row['display_title']), lang='en')))\n",
    "            \n",
    "            #Connect instances with types of documents\n",
    "            doctype = URIRef(row['docty'])\n",
    "            g.add((instance, RDF.type, doctype))\n",
    "    \n",
    "            #Connect instances with country of origin\n",
    "            if row['count'] != \"nan\":\n",
    "                country = URIRef(schema + str(row['count']).replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "                g.add((instance, countryOfOrigin_uri, country))\n",
    "\n",
    "            #Connect instances with projects\n",
    "            if row['projn'] != \"nan\":\n",
    "                project = URIRef(schema + \"project/\" + str(row['projn']).replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "                g.add((instance, isPartOf_uri, project))\n",
    "\n",
    "            #Connect instances with trustfund_keys\n",
    "            if row['trustfund'] != \"nan\":\n",
    "                tf_values = row['trustfund'].split(\",\")\n",
    "                for tf in tf_values:\n",
    "                    trustfund_uri = URIRef(schema + \"trustfund/\" + str(tf).replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "                    g.add((trustfund_uri, RDFS.label, Literal(f\"Trustfund: {tf}\")))\n",
    "                    g.add((instance, isPartOf_uri, trustfund_uri))\n",
    "                    g.add((trustfund_uri, countryOfOrigin_uri, country))\n",
    "                \n",
    "            #Connect instances with authors\n",
    "            author_dict = ast.literal_eval(row['authors'])\n",
    "            for author_dict_entries in author_dict.values():\n",
    "                author_name = author_dict_entries['author']\n",
    "                author_uri = URIRef(schema + \"author/\" + author_name.replace(\" \", \"_\"))\n",
    "                g.add((instance, authoredBy_uri, author_uri))\n",
    "                g.add((author_uri, authored_uri, instance))\n",
    "\n",
    "            #Add abstract\n",
    "            if row['abstracts'] != \"nan\":\n",
    "                abstract_uri = URIRef(schema + \"abstract/\" + str(row['display_title']).replace(\" \",\"_\").replace(\"-\",\"_\"))\n",
    "                g.add((instance, abstractIs_uri, abstract_uri))\n",
    "                g.add((abstract_uri, RDFS.label, Literal(str(row['abstracts']))))\n",
    "                g.add((abstract_uri, RDF.type, abstract_class))\n",
    "                g.add((abstract_uri, isPartOf_uri, abstract_uri))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "89b33b6c-2f9e-413d-8949-d0100a8d4bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevehedden/.local/lib/python3.8/site-packages/rdflib/plugins/serializers/nt.py:35: UserWarning: NTSerializer always uses UTF-8 encoding. Given encoding was: urf-8\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nebe42be5141842bbbd6e8cbc72b14459 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize('SDKG.ttl',format='turtle',prefixes = prefixes, encoding='urf-8')\n",
    "g.serialize(\"SDKG_XML\",format=\"nt\",prefixes = prefixes, encoding='urf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce3f18-2787-4f48-81a1-6dbe3c12db43",
   "metadata": {},
   "source": [
    "## 4. Bring in some additional data from Wikidata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "7d34107c-775f-47c2-bd77-859c4b816372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "def get_property_label(property_code):\n",
    "    # Set up the SPARQL endpoint\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "    # Construct the SPARQL query\n",
    "    query = f\"\"\"\n",
    "    SELECT ?label WHERE {{\n",
    "      wd:{property_code} rdfs:label ?label.\n",
    "      FILTER (lang(?label) = 'en')\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the query and response format\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    # Execute the query and retrieve the results\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    # Extract and return the property label\n",
    "    if 'results' in results and 'bindings' in results['results'] and results['results']['bindings']:\n",
    "        label = results['results']['bindings'][0]['label']['value']\n",
    "        return label\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "f9393199-f82c-490c-9642-7b9bb672c237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 101/101 [09:11<00:00,  5.46s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "\n",
    "# Create a cache to store property code-label mappings\n",
    "property_cache = {}\n",
    "entity_cache = {}\n",
    "\n",
    "# Prepare a list to collect triples for bulk graph update\n",
    "triples = []\n",
    "\n",
    "# Iterate over the URIs and add the properties to the RDF graph\n",
    "for uri in tqdm(df['country_URI']):        \n",
    "    if isinstance(uri, str) and uri.startswith('http://www.wikidata.org/entity/Q'):\n",
    "        class_uri = URIRef(uri)\n",
    "        country_column = df.loc[df['country_URI'] == uri, 'count'].iloc[0]\n",
    "        country_column = URIRef(schema + str(country_column).replace(\" \", \"_\"))\n",
    "        \n",
    "        # Construct the SPARQL query\n",
    "        qid = uri.split('/')[-1]\n",
    "        query = f\"\"\"\n",
    "        SELECT ?prop ?value WHERE {{\n",
    "          wd:{qid} ?prop ?value .\n",
    "          OPTIONAL {{ ?prop rdfs:label ?label . FILTER(lang(?label) = 'en') }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "        # Set the query and response format\n",
    "        sparql.setQuery(query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "\n",
    "        # Execute the query and retrieve the results\n",
    "        results = sparql.query().convert()\n",
    "\n",
    "        # Iterate over the results and add them to the RDF graph\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            prop = result[\"prop\"][\"value\"]\n",
    "            value = Literal(result[\"value\"][\"value\"])\n",
    "            triple = (country_column, None, None)  # Placeholder for triple\n",
    "            \n",
    "            if prop.startswith('http://www.wikidata.org/prop'):\n",
    "                property_code = prop.split('/')[-1]\n",
    "                # Check if the property code is already in the cache\n",
    "                if property_code in property_cache:\n",
    "                    property_label = property_cache[property_code]\n",
    "                else:\n",
    "                    # If not in cache, query and retrieve the property label\n",
    "                    property_label = get_property_label(property_code)\n",
    "                    # Store the property code-label mapping in the cache\n",
    "                    property_cache[property_code] = property_label\n",
    "                \n",
    "                property_label_URI = URIRef(schema + property_label.replace(\" \", \"_\"))\n",
    "                triple = (country_column, property_label_URI, value)\n",
    "            \n",
    "            if value.startswith('http://www.wikidata.org/entity/Q'):\n",
    "                entity_code = value.split('/')[-1]\n",
    "                # Check if the entity code is already in the cache\n",
    "                if entity_code in entity_cache:\n",
    "                    entity_label = entity_cache[entity_code]\n",
    "                else:\n",
    "                    # If not in cache, query and retrieve the entity label\n",
    "                    entity_label = get_entity_label(entity_code)\n",
    "                    # Store the entity code-label mapping in the cache\n",
    "                    entity_cache[entity_code] = entity_label\n",
    "\n",
    "                entity_label_URI = URIRef(schema + str(entity_label).replace(\" \", \"_\"))\n",
    "                triple = (country_column, property_label_URI, entity_label_URI)\n",
    "            \n",
    "            triples.append(triple)\n",
    "        \n",
    "    elif isinstance(uri, float) and np.isnan(uri):\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Add all collected triples to the RDF graph in bulk\n",
    "for subject, predicate, object_ in triples:\n",
    "    if predicate is not None:\n",
    "        g.add((subject, predicate, object_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "64942b40-7bfe-4887-a7b3-1bb887248af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N213871fefdbd4948b878115aba5fa456 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize('SDKG.ttl',format='turtle',prefixes = prefixes, encoding='urf-8')\n",
    "#g.serialize(\"SDKG_nt\",format=\"nt\",prefixes = prefixes, encoding='urf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fadd7d3-481d-44ef-9021-b8b6a76fb1ca",
   "metadata": {},
   "source": [
    "## 5. Query KG using SPARQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "dd3eccf9-c62e-4448-bb4d-e4c87ae882b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N0765c2ce23854b96a2112e0080a699b5 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rdflib\n",
    "g = rdflib.Graph()\n",
    "g.parse(\"path to your KG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "fbb1d6ff-d016-47b8-9213-abe38864c45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: http://schema.org/doc/Brazil___LATIN_AMERICA_AND\n",
      "____________CARIBBEAN___P107146___Acre_Social_and_Economic_Inclusion_and\n",
      "____________Sustainable_Development_Project___PROACRE___Audited\n",
      "____________Financial_Statement\n",
      "Document ID: http://schema.org/doc/Brazil___LATIN_AMERICA_AND\n",
      "____________CARIBBEAN___P167455___Ceara_Rural_Sustainable_Development\n",
      "____________and_Competitiveness_Phase_II___Audited_Financial_Statement\n",
      "Document ID: http://schema.org/doc/Concept_Environmental_and_Social\n",
      "____________Review_Summary_(ESRS)___Mato_Grosso_Sustainable_Development\n",
      "____________of_Family_Farming___P175723\n",
      "Document ID: http://schema.org/doc/Brazil___Acre_Social_and_Economic\n",
      "____________Inclusion_and_Sustainable_Development_Project___PROACRE\n",
      "Document ID: http://schema.org/doc/Brazil___Mato_Grosso_Fiscal\n",
      "____________Adjustment_and_Environmental_Sustainability_Development\n",
      "____________Policy_Loan\n",
      "Document ID: http://schema.org/doc/Disclosable_Version_of_the_ISR__\n",
      "____________Ceara_Rural_Sustainable_Development_and_Competitiveness\n",
      "____________Phase_II___P167455___Sequence_No_:_06\n",
      "Document ID: http://schema.org/doc/Disclosable_Version_of_the_ISR__\n",
      "____________Ceara_Rural_Sustainable_Development_and_Competitiveness\n",
      "____________Phase_II___P167455___Sequence_No_:_07\n",
      "Document ID: http://schema.org/doc/Disclosable_Version_of_the_ISR__\n",
      "____________Ceara_Rural_Sustainable_Development_and_Competitiveness\n",
      "____________Phase_II___P167455___Sequence_No_:_08\n",
      "Document ID: http://schema.org/doc/Disclosable_Version_of_the_ISR__\n",
      "____________Rio_de_Janeiro_Adjustment_and_Sustainable_Development_Policy\n",
      "____________Loan___P178729___Sequence_No_:_01\n",
      "Document ID: http://schema.org/doc/Brazil___LATIN_AMERICA_AND\n",
      "____________CARIBBEAN__P107146__Acre_Social_and_Economic_Inclusion_and\n",
      "____________Sustainable_Development_Project___PROACRE___Procurement_Plan\n",
      "Document ID: http://schema.org/doc/Brazil___LATIN_AMERICA_AND\n",
      "____________CARIBBEAN__P167455__Ceara_Rural_Sustainable_Development_and\n",
      "____________Competitiveness_Phase_II___Procurement_Plan\n",
      "Document ID: http://schema.org/doc/Brazil___Rio_de_Janeiro\n",
      "____________Adjustment_and_Sustainable_Development_Policy_Loan\n",
      "Document ID: http://schema.org/doc/Appraisal_Program_Information\n",
      "____________Document_(PID)___Rio_de_Janeiro_Adjustment_and_Sustainable\n",
      "____________Development_Policy_Loan___P178729\n",
      "Document ID: http://schema.org/doc/Concept_Program_Information\n",
      "____________Document_(PID)___Rio_de_Janeiro_Adjustment_and_Sustainable\n",
      "____________Development_Policy_Loan___P178729\n",
      "Document ID: http://schema.org/doc/Concept_Program_Information\n",
      "____________Document_(PID)___Rio_de_Janeiro_Fiscal_Management_and\n",
      "____________Sustainable_Development_Policy_Loan___P179182\n",
      "Document ID: http://schema.org/doc/Concept_Project_Information\n",
      "____________Document_(PID)___Mato_Grosso_Sustainable_Development_of\n",
      "____________Family_Farming___P175723\n",
      "Document ID: http://schema.org/doc/Stakeholder_Engagement_Plan_(SEP)\n",
      "____________Mato_Grosso_Sustainable_Development_of_Family_Farming_(P175723)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Find the URI of Brazil in your ontology\n",
    "brazil_uri = \"<http://schema.org/Brazil>\"  # Replace with the actual URI\n",
    "\n",
    "# Step 2: Find the most relevant documents related to Brazil\n",
    "documents_query = f\"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "SELECT ?document\n",
    "WHERE {{\n",
    "  ?document a/rdfs:subClassOf* schema:world_bank_document ;\n",
    "      schema:countryOfOrigin {brazil_uri} .\n",
    "\n",
    "}}\n",
    "\"\"\"\n",
    "qres = g.query(documents_query)\n",
    "for row in qres:\n",
    "    print(f\"Document ID: {row.document}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "d94f956e-5e88-4c3b-b240-c7800aa3ceb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: http://schema.org/author/World_Bank, Number of Documents: 5\n",
      "Author: http://schema.org/author/Ru,Jiang, Number of Documents: 4\n",
      "Author: http://schema.org/author/Tesfaye,Roman, Number of Documents: 3\n",
      "Author: http://schema.org/author/Techane,Meron_Tadesse, Number of Documents: 2\n",
      "Author: http://schema.org/author/Noronha_Farinelli,Barbara_Cristina, Number of Documents: 2\n",
      "Author: http://schema.org/author/Paviot,Marie_Caroline, Number of Documents: 2\n",
      "Author: http://schema.org/author/Aragaw_Biru, Number of Documents: 2\n",
      "Author: http://schema.org/author/Zaourak,Gabriel_Roberto, Number of Documents: 2\n",
      "Author: http://schema.org/author/Estela_Alejandra_Marcolongo, Number of Documents: 1\n",
      "Author: http://schema.org/author/Glauber_Pinheiro_de_Aquino, Number of Documents: 1\n",
      "Author: http://schema.org/author/Liduina_Cynthya_Lemos, Number of Documents: 1\n",
      "Author: http://schema.org/author/Di_Crocco,Paula_Agostina, Number of Documents: 1\n",
      "Author: http://schema.org/author/Lencina,Fernando_Andres, Number of Documents: 1\n",
      "Author: http://schema.org/author/Santos_Lima,Eirivelthon, Number of Documents: 1\n",
      "Author: http://schema.org/author/Colbano,Fabiano_Silvio, Number of Documents: 1\n",
      "Author: http://schema.org/author/Daniel_Larrache, Number of Documents: 1\n",
      "Author: http://schema.org/author/Andrey_Macedo_de_Araujo, Number of Documents: 1\n",
      "Author: http://schema.org/author/ELAINY_CRISTINA_PINHEIRO_VIEIRA, Number of Documents: 1\n",
      "Author: http://schema.org/author/Lafaete_Almeida_de_Oliveira, Number of Documents: 1\n",
      "Author: http://schema.org/author/Lafaete_Almenida_de_Oliveira_Mesquita, Number of Documents: 1\n",
      "Author: http://schema.org/author/Waksberg_Guerrini,Ana, Number of Documents: 1\n",
      "Author: http://schema.org/author/Borrowing_Agency, Number of Documents: 1\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Graph, RDF, RDFS, URIRef\n",
    "\n",
    "# Step 1: Find the URI of the basic_form_of_government you are interested in\n",
    "government_form_uri = \"<http://schema.org/federal_republic>\"  # Replace with the actual URI\n",
    "\n",
    "# Step 2: Query for authors who have written the most documents associated with countries having the basic_form_of_government as \"federal_republic\"\n",
    "authors_query = f\"\"\"\n",
    "PREFIX schema: <http://schema.org/>\n",
    "PREFIX prop: <http://schema.org/property>\n",
    "SELECT ?author (COUNT(?document) AS ?numDocuments)\n",
    "WHERE {{\n",
    "  ?document a/rdfs:subClassOf* schema:world_bank_document ;\n",
    "            schema:countryOfOrigin [\n",
    "                    schema:basic_form_of_government {government_form_uri}\n",
    "            ] ;\n",
    "            schema:authoredBy ?author .\n",
    "}}\n",
    "GROUP BY ?author\n",
    "ORDER BY DESC(?numDocuments)\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "results = g.query(authors_query)\n",
    "\n",
    "# Now you can process the results and present them as needed (e.g., using pandas DataFrames)\n",
    "# For simplicity, here, I'm just printing the author names and the number of documents they wrote\n",
    "for row in results:\n",
    "    print(f\"Author: {row.author}, Number of Documents: {row.numDocuments}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07625494-919e-45d6-aa54-fce95f4fac32",
   "metadata": {},
   "source": [
    "## 6. Compare the different ways of interacting with data: using SPARQL queries on the RDF, putting raw metadata into LlamaIndex, and putting the RDF data into LlamaIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a722781-d1ba-44f3-bb51-1c7c690a9cf0",
   "metadata": {},
   "source": [
    "### Putting raw data into LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "94cb7f48-561d-46b8-a11a-24be3b353a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, ServiceContext, LLMPredictor\n",
    "from langchain import OpenAI\n",
    "import os \n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = <YOUR API KEY>  # replace with yours\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "#Make sure your raw.csv file is in the data folder\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "\n",
    "index = GPTVectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "48b1d499-d501-4b67-b5e1-fafbe8b8cd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brazil - LATIN AMERICA AND CARIBBEAN - P126452 - Rio Grande do Norte: Regional Development and Governance - Audited Financial Statement\n",
      "Brazil - LATIN AMERICA AND CARIBBEAN- P158000- Amazon Sustainable Landscapes Project - Procurement Plan\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Show me all of the World Bank documents in the context information about Brazil\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "80ac86de-1b72-4339-a025-8f254f3f5ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corsi,Anna has not written any documents based on the context information.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Based on the context information, what documents has Corsi,Anna written?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "f97995c4-6dfb-455f-8834-758988f0ecb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anna Corsi is not mentioned in the context information.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me more about Anna Corsi\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "fa1bb2eb-a6df-4736-83bd-bd933e474353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The World Bank does not appear to have a land management infrastructure project in Turkey.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me more about World Bank's land management infrastructure project in Turkey\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278578b-a3b4-46a6-9756-3e7f4f078466",
   "metadata": {},
   "source": [
    "### Putting RDF data into LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "c702f006-562d-4078-80d9-67d71740148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import GPTVectorStoreIndex, download_loader\n",
    "\n",
    "RDFReader = download_loader(\"RDFReader\")\n",
    "document = RDFReader().load_data(file=\"SDKG_nt\")\n",
    "\n",
    "# Define LLM\n",
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-davinci-002\"))\n",
    "\n",
    "# NOTE: set a chunk size limit to < 1024 tokens \n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, chunk_size_limit=1012)\n",
    "\n",
    "index = GPTVectorStoreIndex.from_documents(document, service_context=service_context)\n",
    "\n",
    "query_engine = index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "5d8b88db-a132-4c83-a934-cd8294d33c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Brazil - LATIN AMERICA AND CARIBBEAN - P107146 - Acre Social and Economic Inclusion and Sustainable Development Project - PROACRE - Audited Financial Statement>\n",
      "<Disclosable Version of the ISR - Rio de Janeiro Adjustment and Sustainable Development Policy Loan - P178729 - Sequence No : 01>\n",
      "<Grosso Fiscal Adjustment and Environmental Sustainability Development Policy Loan>\n",
      "<Disclosable Version of the ISR - Matanza-Riachuelo Basin Sustainable Development Project - P105680 - Sequence No : 29>\n",
      "<Disclosable Version of the ISR - Matanza-Riachuelo Basin Sustainable Development Project - P105680 - Sequence No : 30>\n",
      "<Disclosable Restructuring Paper - Health Sustainable Development Goals Program-for-Results - P123531>\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Show me all of the World Bank documents in the context information about Brazil\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "7d916450-c22c-48c4-a3c1-84399912aa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concept Project Information Document (PID) - Land administration infrastructure for green and sustainable development - P179217\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Based on the context information, what documents has Corsi,Anna written?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "ab2c4840-96b5-4261-9243-141a0fb2fffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anna Corsi is an author of the document \"Concept Project Information Document (PID) - Land administration infrastructure for green and sustainable development - P179217\". This document is about a project to support the development of a mass valuation system in Turkey and generate market values for individual property units. Corsi is also the author of \"The Time is Now : How Can Uzbekistan Leverage Urbanization as a Driver of Sustainable Development?\", a document about how Uzbekistan can use urbanization to promote sustainable development.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me more about Anna Corsi\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "93a8cc4a-b65b-4362-b980-e51853523d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The objective of the Land Management Infrastructure for Green and Sustainable Development Project is to improve the accuracy and accessibility of land administration information in Turkiye. There are three components to the project, the first component being creating 3D city models and updating cadastre data. This component will support: (i) the creation of 3D city models based on the proven approach tested in the Amasya pilot; and (ii) the completion of the update and verification of cadastral data for 6 million parcels (out of the total remaining 11 million parcels19 not covered by LRCMP), in both urban and rural areas. As part of the cadastre updating activities, capacity building programs for addressing challenges concerning women’s land rights and ownership will be discussed with TKGM to determine how to better address these issues as part of the public consultation step during the surveying process. While activities on the update and verification of cadastral data will be carried out in both urban and rural areas, for the creation of 3D city models, the Project will cover major urban areas (approximately 40,000 km, almost all urban areas in the country) in all 81 provinces in Turkiye. As part of these activities, the project will finance the completion and renewal\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me more about World Bank's land management infrastructure project in Turkey\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdea400-a9c6-471c-92e8-3a46a40626a6",
   "metadata": {},
   "source": [
    "### Try using both RDF and raw data to see if it helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "c30c27c2-298a-481e-ba10-309c302badc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Make sure to update the files in the data folder\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "\n",
    "index = GPTVectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "4e67f4f1-9fe5-4143-8fac-ad252426fd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Brazil - LATIN AMERICA AND CARIBBEAN - P126452 - Rio Grande do Norte: Regional Development and Governance - Audited Financial Statement\n",
      "Brazil - LATIN AMERICA AND CARIBBEAN- P158000- Amazon Sustainable Landscapes Project - Procurement Plan\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Show me all of the World Bank documents in the context information about Brazil\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "e5c9b01b-be40-4e4d-b9b2-a8d11f55ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corsi,Anna has not written any documents based on the context information.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Based on the context information, what documents has Corsi,Anna written?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "78b3a7ad-a6ce-45e1-9d13-776dec111df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corsi,Anna is not mentioned in the context information provided.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me more about Corsi,Anna\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "65b6f9c9-6a45-472c-aec0-ad0fb52a4dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The World Bank does not appear to have a land management infrastructure project in Turkey.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me more about World Bank's land management infrastructure project in Turkey\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36faf3a5-b361-40a2-84f7-24a877be38c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
